# -*- coding: utf-8 -*-
"""local_planner.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19wN578XNRCx93LqaX6scIoJ-u23ZTINH
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/'My Drive'/

import numpy as np
import cv2
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset

"""
  128 * 128
  
  input : [map , size / 8]
  
  reward : gain * distance_to_goal, K^2, 
  cubic splines used as arc : [K_0, K_f, theta_0, theta_f, p_0, p_f, s1, s2, s3]
  arc : []
  velocity : continous vector 2D
  Q(s, a)(lambda)
  experience play


  implement actor-critic network

  action_space = choice from 7 different continious curve + 3 different arc lengths
  A2C


"""

# train in stages:
#    -> first network learns to find target
#    -> second network learns to find target in a block or fortresses
#    -> generate maze to tackle this problem

class mapGen(object):
  def __init__(self):
    self.size_x = config.size_x
    self.size_y = config.size_y

  def gen(self, level):
    if self.size_y < 25:
      return None
    
    if level == 0:
      xs, ys = np.random.randint(self.size_x, size=1)[0], np.random.randint(self.size_y, size=1)[0]
      xe, ye = np.random.randint(self.size_x, size=1)[0], np.random.randint(self.size_y, size=1)[0]
      return np.zeros((self.size_x, self.size_y)), xs, ys, xe, ye
    if level == 1:
      map = np.zeros((self.size_x, self.size_y))
      x, y = np.random.randint(20, self.size_y - 20, size=2)
      while 8 * abs(x - y) < self.size_y:
         x, y = np.random.randint(20, self.size_y - 20, size=2)
      map[:self.size_x // 2, x-10:x+10] = 1.0
      map[self.size_x // 2:, y-10:y+10] = 1.0
      
      xs = np.random.randint(self.size_x, size=1)[0]
      ys = np.random.randint(self.size_y, size=1)[0]
      while abs(ys - x) < 6 or abs(ys - y) < 6:
        ys = np.random.randint(self.size_y, size=1)[0]
      
      xe = np.random.randint(self.size_x, size=1)[0]
      ye = np.random.randint(self.size_y, size=1)[0]
      while abs(ye - x) <  6 or abs(ye - y) < 6:
        ye = np.random.randint(self.size_y, size=1)[0]
            
      return map
    
    else:
      return None

mgen = mapGen(128, 128)

map, xs, ys, xe, ye = mgen.gen(0)

window = 2

map[xs - window : xs + window, ys - window : ys + window] = 0.5

map[xe - window : xe + window, ye - window : ye + window] = 1.0

plt.imshow(map)

# ideally should output a matrix of p(curve_choice, arc_length  / state)
# but we assume independence conditioned on state
# what will be the implication of sharing initial conv_layer between actor and critic.
# Grads are added from two different nets which can cause covariance shift in the forward layers.
# Common representation of feature ? Who is enforcing that?
# [3, 6, 12, 24, 48, 96, 192]
# [128, 64, 32, 16, 8, 4, 1]
# 1 * 1 * 192

class config:
  size_x = 128
  size_y = 128
  conv_size = [3, 6, 12, 24, 48, 96, 192]
  num_actions = [7, 4]

class Actor(nn.Module):
  def __init__(self):
    super(Actor, self).__init__()
    self.size_x = config.size_x
    self.size_y = config.size_y 

    self.conv = nn.ModuleList()
    self.pool = nn.ModuleList()
    self.batch_norm = nn.ModuleList()
    
    for i in range(1, len(config.conv_size) - 1):
      self.conv.append(nn.Conv2d(config.conv_size[i-1], config.conv_size[i], kernel_size=3, padding=1))
      self.pool.append(nn.MaxPool2d(kernel_size=2, stride=2))
      self.batch_norm.append(nn.BatchNorm2d(config.conv_size[i]))
    
    self.conv.append(nn.Conv2d(config.conv_size[-2], config.conv_size[-1], kernel_size=4))
    self.batch_norm.append(nn.BatchNorm2d(config.conv_size[-1]))
    self.leakyRelu = nn.LeakyReLU(0.2)
    
    self.dropout_1 = nn.Dropout(0.5)
    self.dropout_2 = nn.Dropout(0.2)
    self.dropout_3 = nn.Dropout(0.2)
    
    self.mlp_1 = nn.Linear(config.conv_size[-1], config.conv_size[-1] // 2)
    self.mlp_2 = nn.Linear(config.conv_size[-1] // 2, 32)
    self.mlp_3 = nn.Linear(32, config.num_actions[0])
    self.mlp_4 = nn.Linear(config.conv_size[-1] // 2, 16)
    self.mlp_5 = nn.Linear(16, config.num_actions[1])
    self.flatten = nn.Flatten()
  
  def forward(self, state):
    x = state.to(device)
        
    for i in range(len(self.conv) - 1):
      x = self.conv[i](x)
      x = self.leakyRelu(x)
      x = self.pool[i](x)
      x = self.batch_norm[i](x)
    
    x = self.conv[-1](x)
    x = self.leakyRelu(x)
    x = self.batch_norm[-1](x)
    x = self.flatten(x)
    
    x = self.mlp_1(x)
    x = self.leakyRelu(x)
    xs = self.dropout_1(x)
    
    x = self.mlp_2(xs)
    x = self.leakyRelu(x)
    x = self.dropout_2(x)

    x_ret = self.mlp_3(x)

    x = self.mlp_4(xs)
    x = self.leakyRelu(x)
    x = self.dropout_3(x)

    y_ret = self.mlp_4(x)

    return x_ret, y_ret

class Critic(nn.Module):
  def __init__(self, config):
    super(Critic, self).__init__()
    self.size_x = config.size_x
    self.size_y = config.size_y 

    self.conv = nn.ModuleList()
    self.pool = nn.ModuleList()
    self.batch_norm = nn.ModuleList()
    
    for i in range(1, len(config.conv_size) - 1):
      self.conv.append(nn.Conv2d(config.conv_size[i-1], config.conv_size[i], kernel_size=3, padding=1))
      self.pool.append(nn.MaxPool2d(kernel_size=2, stride=2))
      self.batch_norm.append(nn.BatchNorm2d(config.conv_size[i]))
    
    self.conv.append(nn.Conv2d(config.conv_size[-2], config.conv_size[-1], kernel_size=4))
    self.batch_norm.append(nn.BatchNorm2d(config.conv_size[-1]))
    self.leakyRelu = nn.LeakyReLU(0.2)
    self.dropout_1 = nn.Dropout(0.5)
    self.dropout_2 = nn.Dropout(0.3)
    self.mlp_1 = nn.Linear(config.conv_size[-1], 64)
    self.mlp_2 = nn.Linear(64, 32)
    self.mlp_3 = nn.Linear(32, 1)

  def forward(self, state):
    x = state.to(device)
    
    for i in range(len(self.conv) - 1):
      x = self.conv[i](x)
      x = self.leakyRelu(x)
      x = self.pool[i](x)
      x = self.batch_norm[i](x)
    
    x = self.conv[-1](x)
    x = self.leakyRelu(x)
    x = self.batch_norm[-1](x)
    x = self.flatten(x)

    x = self.mlp_1(x)
    x = self.leakyRelu(x)
    x = self.dropout_1(x)

    x = self.mlp_2(x)
    x = self.leakyRelu(x)
    x = self.dropout_2(x)
    
    x = self.mlp_3(x)

    return x

# self.embedding = nn.Linear(sum(config.num_action), 32, bias=False)
# a = self.embedding(a)
# x = torch.cat([x, a], 1)

# use dual network for better stability
def train_network(state, actor, critic, actor_optim, critic_optim):
  # generate trajectory and train in online learning using pi[theta]
  actor.train()
  critic.train()

  for i in range(max_it):
    dist_1, dist_2 = actor.forward(state)
    value = critic.forward(state)
    prob_curve = F.softmax(dist_1)
    prob_length = F.softmax(dist_2)
    
    prob_curve.detach()
    prob_length.detach()

    c1 = np.random.choice(config.num_action[0], p=prob_curve)
    c2 = np.random.choice(config.num_action[1], p=prob_length)
    
    env.step()



